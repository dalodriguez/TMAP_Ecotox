{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfe631b",
   "metadata": {},
   "source": [
    "# PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a831e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from rdkit.Chem import DataStructs\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.sparse import csc_matrix\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d19e57",
   "metadata": {},
   "source": [
    "# INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Data/'        \n",
    "x = pd.read_csv(os.path.join(folder_path, 'x.csv')).values.flatten()  \n",
    "y = pd.read_csv(os.path.join(folder_path, 'y.csv')).values.flatten()   \n",
    "s = pd.read_csv(os.path.join(folder_path, 's.csv')).values.flatten()  \n",
    "t = pd.read_csv(os.path.join(folder_path, 't.csv')).values.flatten()   \n",
    "with open(\"/Data/morgan_fps.pkl\", \"rb\") as f:\n",
    "    morgan = pickle.load(f)\n",
    "\n",
    "table_cat = pd.read_csv('/Data/table_cat.csv',index_col=0, encoding='utf-8')\n",
    "\n",
    "with open(\"/Data/table_num.pkl\", \"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "table_num = obj[\"matrix\"]\n",
    "colnames = obj[\"colnames\"]\n",
    "rownames = obj[\"rownames\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4fc63",
   "metadata": {},
   "source": [
    "# FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14384a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_connected_nodes(index, x, y, G, k=50):\n",
    "    visited = {index}\n",
    "    heap = []\n",
    "    result = [index] \n",
    "    x0, y0 = x[index], y[index]\n",
    "    for nbr in G.neighbors(index):\n",
    "        dx = x[nbr] - x0\n",
    "        dy = y[nbr] - y0\n",
    "        dist = dx*dx + dy*dy \n",
    "        heapq.heappush(heap, (dist, nbr))\n",
    "    while heap and len(result) < k + 1:  \n",
    "        dist, node = heapq.heappop(heap)\n",
    "        if node in visited:\n",
    "            continue\n",
    "        visited.add(node)\n",
    "        result.append(node)\n",
    "        for nbr in G.neighbors(node):\n",
    "            if nbr not in visited:\n",
    "                dx = x[nbr] - x0\n",
    "                dy = y[nbr] - y0\n",
    "                d = dx*dx + dy*dy\n",
    "                heapq.heappush(heap, (d, nbr))\n",
    "    return result\n",
    "\n",
    "def plot_knn(neighbors, x, y, s, t, distance=0.01):\n",
    "    xaxis = x[neighbors[0]]\n",
    "    yaxis = y[neighbors[0]]\n",
    "    xlim = [xaxis - distance, xaxis + distance]\n",
    "    ylim = [yaxis - distance, yaxis + distance]\n",
    "\n",
    "    gradient = range(len(neighbors))\n",
    "    cmap = plt.cm.viridis\n",
    "    colors = [cmap(i / (len(neighbors) - 1)) for i in gradient]\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(zip(s, t))\n",
    "    for u, v in G.edges():\n",
    "        if u in neighbors or v in neighbors:\n",
    "            ax.plot([x[u], x[v]], [y[u], y[v]], color='gray', alpha=0.5)\n",
    "\n",
    "    ax.scatter(x, y, s=10, color='lightblue', label='All nodes')\n",
    "    for i, node in enumerate(neighbors):\n",
    "        ax.scatter(x[node], y[node], color=colors[i], s=50, zorder=5)\n",
    "        ax.text(x[node], y[node], str(i), fontsize=8, ha='left', va='bottom')\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=0, vmax=len(neighbors)-1))\n",
    "    sm.set_array([])\n",
    "    plt.colorbar(sm, ax=ax, label='Order')\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    plt.show()\n",
    "\n",
    "def k_similarity_matrix(neighbors, morgan):\n",
    "    morgan_subset = [morgan[m] for m in neighbors]\n",
    "    n = len(morgan_subset)\n",
    "    sim_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            sim_matrix[i, j] = DataStructs.TanimotoSimilarity(morgan_subset[i], morgan_subset[j])\n",
    "    return sim_matrix\n",
    "\n",
    "def decay_curve(sim_matrix, sigma=2):\n",
    "    smoothed = gaussian_filter1d(sim_matrix[0], sigma=sigma)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(smoothed, linewidth=2)\n",
    "    plt.xlabel('k-NN Index')\n",
    "    plt.ylabel('Tanimoto Similarity')\n",
    "    plt.show()\n",
    "\n",
    "def process_row(row_data, G, depth):\n",
    "    idx, row, iteration_number = row_data\n",
    "    target_index = idx\n",
    "    # Get connected neighbors using BFS\n",
    "    connected_neighbors = list(nx.bfs_edges(G, source=target_index, depth_limit=depth))\n",
    "    connected_nodes = {target_index} | {node for edge in connected_neighbors for node in edge}\n",
    "    expvalue = row['features']\n",
    "    # Create subgraph and calculate distances\n",
    "    subgraph_nodes = list(connected_nodes)\n",
    "    subgraph = G.subgraph(subgraph_nodes)\n",
    "    distances = nx.single_source_shortest_path_length(subgraph, target_index)\n",
    "    max_distance = max(distances.values())\n",
    "    # Initialize array for this iteration\n",
    "    values = np.zeros(G.number_of_nodes())\n",
    "    # Vectorized imputation\n",
    "    if expvalue > 0:\n",
    "        for node, dist in distances.items():\n",
    "            values[node] = expvalue * np.exp(-dist / max_distance)\n",
    "    else:\n",
    "        for node, dist in distances.items():\n",
    "            values[node] = expvalue * np.exp(-dist / max_distance)\n",
    "    return values\n",
    "\n",
    "def calculate_imputed_values(depth, index, table_num, features,s,t):\n",
    "    rownames = features\n",
    "    column_values = table_num[:, index].toarray().flatten()\n",
    "    df = pd.DataFrame({'chemicals': rownames, 'features': column_values})\n",
    "    df_filtered = df[df['features'] != 0]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(zip(s, t))\n",
    "    # Prepare data for parallel processing\n",
    "    row_data = [(idx, row, df_filtered.index.get_loc(idx) + 1) \n",
    "                for idx, row in df_filtered.iterrows()]\n",
    "    # Initialize the results array\n",
    "    results = np.zeros((len(df_filtered), len(column_values)))\n",
    "    # Use parallel processing\n",
    "    with mp.Pool() as pool:\n",
    "        process_func = partial(process_row, G=G, depth=depth)\n",
    "        chunk_size = max(1, len(row_data) // mp.cpu_count())\n",
    "        \n",
    "        for i, result in enumerate(pool.imap(process_func, row_data, chunksize=chunk_size)):\n",
    "            if (i) % 100 == 0:\n",
    "                print(f\"Iteration {i + 1} over {df_filtered.shape[0]}\")\n",
    "            results[i] = result\n",
    "    print('Calculating mean of imputed values...')\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        nonzero_count = np.count_nonzero(results, axis=0)\n",
    "        mean_imputed_values = np.where(nonzero_count > 0,np.sum(results, axis=0) / nonzero_count, 0)\n",
    "    df['features_imputed'] = mean_imputed_values\n",
    "    df.loc[df['features'] != 0, 'features_imputed'] = df['features']\n",
    "    return df['features_imputed'].values\n",
    "\n",
    "def plot_imputed_values(imputed_data,table_cat,x,y,s,t,feature):\n",
    "    df = pd.DataFrame({\n",
    "        'Column_Data': imputed_data,\n",
    "        'Common_Name': table_cat['ID_CommonName'].values,\n",
    "        'x': x,\n",
    "        'y': y\n",
    "    })\n",
    "    vmin, vmax = df['Column_Data'].min(), df['Column_Data'].max()\n",
    "    print(f\"Value range: min={vmin:.3f}, max={vmax:.3f}\")\n",
    "    colors = [\n",
    "        (-1.0, \"#0a5a64\"),\n",
    "        (0.0, \"#ececec\"),\n",
    "        (1.0, \"#64140a\")\n",
    "    ]\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\n",
    "        \"blue_grey_red\",\n",
    "        [c[1] for c in colors],\n",
    "        N=256\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    segments = [\n",
    "        [(x[s[i]], y[s[i]]), (x[t[i]], y[t[i]])]\n",
    "        for i in range(len(s))\n",
    "    ]\n",
    "    scatter = ax.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        zorder=2,\n",
    "        s=1,\n",
    "        c=df['Column_Data'],\n",
    "        cmap=custom_cmap,\n",
    "        vmin=-1,\n",
    "        vmax=1\n",
    "    )\n",
    "    ax.set_title(feature)\n",
    "    ax.axis('off')\n",
    "    plt.colorbar(scatter, ax=ax, label='Value')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e8aa9",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d44578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PARAMS\n",
    "index = 20\n",
    "k = 50\n",
    "\n",
    "# FIND AND PLOT THE kNNs\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(zip(s, t))\n",
    "neighbors = get_closest_connected_nodes(index, x, y, G, k)\n",
    "plot_knn(neighbors, x, y, s, t, distance=0.01)\n",
    "\n",
    "# COMPUTE SIMILARITY MATRIX AND PRODUCE DECAY CURVE\n",
    "sim_matrix = k_similarity_matrix(neighbors, morgan)\n",
    "decay_curve(sim_matrix, sigma=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPUTATION AND PLOTTING\n",
    "feature = 'HTGene_ESR1'\n",
    "feature_index =  colnames.index(feature)\n",
    "imputed_data = calculate_imputed_values(depth=50, index=feature_index, table_num=table_num, features=rownames, s=s, t=t)\n",
    "plot_imputed_values(imputed_data,table_cat,x,y,s,t,feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
